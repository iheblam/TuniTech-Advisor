# ğŸ“Š Week 2: ML Pipeline Development - Complete Summary

## ğŸ¯ Objectives Achieved

Week 2 focused on building a complete machine learning pipeline from data preprocessing to experiment tracking with MLflow. We successfully transformed our raw smartphone data into a production-ready recommendation system.

---

## ğŸ“‚ Deliverables

### 1. **Notebooks** (Cleaned & Simplified)
- `notebooks/01_EDA.ipynb` - Exploratory Data Analysis (Week 1)
- `notebooks/02_ML_Pipeline_Clean.ipynb` - **Complete ML pipeline (simplified from 1,825 to ~400 lines)**

### 2. **Final Dataset**
- `dataset/unified_smartphones.csv` - Original merged data (953 smartphones)
- `dataset/unified_smartphones_filled.csv` - **Final cleaned dataset with smart imputation**

### 3. **Production Models** (Clean & Optimized)
- `models/best_model.pkl` - **Production-ready KNN model (MAE: 4.42 TND)**
- `models/best_model_info.pkl` - Model metadata and performance metrics
- `models/data_splits.pkl` - Train/test splits for reproducibility
- `models/model_comparison.png` - Visual performance comparison

### 4. **MLflow Experiment Tracking**
- `mlruns/` - 7 tracked experiments with full reproducibility
- Complete parameter and metric logging
- Model versioning and easy comparison

---

## ğŸ”¬ ML Pipeline Steps

### **Step 1: Data Preprocessing** âœ…

**Goal**: Clean and prepare data for modeling

**Actions**:
- Loaded unified dataset (953 smartphones with prices)
- Created preprocessing pipeline using scikit-learn:
  - **Numerical features**: KNNImputer (n_neighbors=5) + StandardScaler
  - **Categorical features**: SimpleImputer + OneHotEncoder
- Handled missing values intelligently
- Normalized features for consistent scaling

**Output**: 
- Preprocessed dataset with ~52 features (after one-hot encoding)
- Saved preprocessing pipeline for future predictions

---

### **Step 2: Feature Engineering** âœ…

**Goal**: Create meaningful features to improve prediction accuracy

**Features Created** (14 new features):

#### 1. **Value Metrics**
- `value_score`: Composite score based on RAM, storage, camera, and battery
- `price_per_gb_ram`: Price efficiency metric
- `price_per_gb_storage`: Storage value indicator

#### 2. **Specification Ratios**
- `camera_ratio`: Rear camera / Front camera quality comparison
- `ram_storage_ratio`: Memory balance indicator
- `battery_per_inch`: Battery efficiency per screen size

#### 3. **Combined Features**
- `total_camera_mp`: Sum of all cameras
- `total_specs_score`: Overall device capability score

#### 4. **Price Tiers**
- `price_tier`: Budget (0-700 TND), Mid-range (700-2000), Premium (2000+)

#### 5. **Binary Indicators**
- `is_5g`: Network capability flag
- `is_flagship_brand`: Premium brand indicator (Apple, Samsung)
- `has_high_camera`: Camera quality flag (>40 MP)
- `high_battery`: Battery capacity flag (>4500 mAh)
- `large_screen`: Screen size flag (>6.5 inches)

**Result**: Dataset expanded to 26 features with rich information

---

### **Step 3: Feature Selection** âœ…

**Goal**: Identify most important features for price prediction

**Methods Used**:
1. **Correlation Analysis**: Removed highly correlated features (threshold: 0.85)
2. **Random Forest Feature Importance**: Ranked features by predictive power
3. **Domain Knowledge**: Kept business-critical features

**Selected Features** (7 final features):

**Numerical** (2):
- `value_score` - Most important predictor
- `total_specs_score` - Overall device quality

**Categorical** (5):
- `brand` - Manufacturer impact on price
- `network` - 5G vs 4G pricing difference
- `os` - Android vs iOS market positioning
- `processor_type` - CPU performance indicator
- `price_tier` - Market segment classification

**Impact**: 
- Reduced feature space by 73% (26 â†’ 7 features)
- Maintained prediction accuracy
- Improved model interpretability

---

### **Step 4: Model Training & Evaluation** âœ…

**Goal**: Build and compare multiple regression models

**Models Trained**:

#### 1. **K-Nearest Neighbors (KNN)** ğŸ†
- **Baseline**: n_neighbors=5, weights='distance'
- **Optimized**: n_neighbors=10, weights='distance'
- **Final MAE**: 4.42 TND (after hyperparameter tuning)
- **RÂ² Score**: 0.9998
- **Training Time**: 0.004s
- **Status**: **Best Model**

#### 2. **Random Forest**
- **Parameters**: n_estimators=100, max_depth=20
- **MAE**: 20.75 TND
- **RÂ² Score**: 0.9988
- **Training Time**: 0.89s

#### 3. **XGBoost**
- **Parameters**: n_estimators=100, max_depth=6, learning_rate=0.1
- **MAE**: 17.27 TND
- **RÂ² Score**: 0.9991
- **Training Time**: 0.23s

**Dataset Split**:
- Training: 762 smartphones (80%)
- Testing: 191 smartphones (20%)

**Winner**: KNN (n=10) with **lowest MAE** and **fastest training**

---

### **Step 5: MLflow Integration** âœ…

**Goal**: Track experiments and enable reproducible ML

**Setup**:
- Created MLflow experiment: "TuniTech_Smartphone_Recommender"
- Configured local tracking server
- Implemented automatic logging for all experiments

**What's Tracked**:
- âœ… **Parameters**: All hyperparameters (n_neighbors, max_depth, etc.)
- âœ… **Metrics**: MAE, RMSE, RÂ², training_time
- âœ… **Models**: Complete pipelines with preprocessing
- âœ… **Tags**: model_type, dataset_size, experiment_type
- âœ… **Artifacts**: Saved model files and visualizations

**Experiments Logged** (7 total):
1. KNN Model (baseline)
2. Random Forest Model
3. XGBoost Model
4. KNN_n3 (hyperparameter tuning)
5. KNN_n7 (hyperparameter tuning)
6. KNN_n10 (hyperparameter tuning) â­ **Best**

---

### **Step 5.5: Hyperparameter Tuning** âœ…

**Goal**: Optimize KNN performance through systematic experimentation

**Methodology**:
- Tested n_neighbors: [3, 5, 7, 10, 15]
- All experiments automatically logged to MLflow
- Systematic evaluation across metrics

**Results**:

| n_neighbors | MAE (TND) | RÂ² Score | Training Time |
|-------------|-----------|----------|---------------|
| 3           | 12.22     | 0.9974   | 0.005s       |
| 5           | 7.97      | 0.9988   | 0.006s       |
| 7           | 6.20      | 0.9994   | 0.004s       |
| **10** ğŸ†   | **4.42**  | **0.9998** | **0.004s** |
| 15          | 5.15      | 0.9996   | 0.004s       |

**Key Findings**:
- **45% improvement** from baseline (7.97 â†’ 4.42 TND MAE)
- Optimal configuration: **n_neighbors=10**
- Clear trend: More neighbors = Better accuracy (up to optimal point)
- Minimal impact on training time

**Business Impact**:
- Average prediction error: **4.42 TND** (~0.5% for mid-range phones)
- Highly accurate recommendations for users
- Fast inference for real-time applications

---

## ğŸ“ˆ Overall Performance

### **Final Model Performance**

**Best Model**: KNN with n_neighbors=10

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **MAE** | 4.42 TND | Average error per prediction |
| **RÂ²** | 0.9998 | 99.98% variance explained |
| **Training Time** | 0.004s | Very fast training |
| **Inference Time** | <1ms | Real-time ready |

### **Why KNN Won**:
1. **Best accuracy**: Lowest MAE among all models (4.42 TND)
2. **Fastest training**: 10-20x faster than ensemble methods
3. **Simple & interpretable**: Easy to explain predictions
4. **Scalable**: Efficient for our dataset size (953 phones)
5. **Consistent**: Extremely high RÂ² score (0.9998)

---

## ğŸ“ Key Learnings

### 1. **Feature Engineering is Critical**
- Engineered features (`value_score`, `total_specs_score`) were among top predictors
- Domain knowledge helped create meaningful features
- Feature selection reduced complexity without sacrificing accuracy

### 2. **Simpler Models Can Win**
- KNN outperformed complex ensemble methods (RF, XGBoost)
- Training time matters for iterative development
- Interpretability is valuable for business stakeholders

### 3. **Hyperparameter Tuning Matters**
- 44% improvement from optimal hyperparameters
- MLflow made systematic experimentation easy
- Data-driven decision making > intuition

### 4. **MLflow is Essential**
- Complete experiment reproducibility
- Easy model comparison and versioning
- Professional ML workflow from day one

---

## ğŸ”§ Technical Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Data Processing** | Pandas, NumPy | Data manipulation and analysis |
| **ML Framework** | Scikit-learn | Pipelines, models, preprocessing |
| **Gradient Boosting** | XGBoost | Advanced ensemble model |
| **Experiment Tracking** | MLflow | Model versioning and comparison |
| **Visualization** | Matplotlib, Seaborn | Charts and insights |
| **Development** | Jupyter Notebook | Interactive development |

---

## ğŸ“Š Data Flow Summary

```
Raw Data (953 phones with prices)
    â†“
Smart Imputation â†’ Fill missing specs
    â†“
Preprocessing Pipeline â†’ KNNImputer + StandardScaler (Numerical)
                      â†’ SimpleImputer + OneHotEncoder (Categorical)
    â†“
Feature Engineering â†’ 14 new features created
                   â†’ value_score, total_specs_score, price_tier, etc.
    â†“
Feature Selection â†’ 7 optimal features selected
                 â†’ 2 numerical + 5 categorical
    â†“
Train/Test Split â†’ 762 / 191 (80/20)
    â†“
Model Training â†’ KNN, Random Forest, XGBoost
    â†“
Hyperparameter Tuning â†’ n_neighbors: 3, 5, 7, 10, 15
    â†“
Best Model Selection â†’ KNN (n=10, MAE=4.42 TND)
    â†“
MLflow Tracking â†’ 7 experiments logged
    â†“
Production Ready Model âœ…
```

---

## ğŸ‰ Week 2 Achievements

1. âœ… Built production-ready ML pipeline (simplified to 400 lines)
2. âœ… Achieved 99.98% prediction accuracy (RÂ²=0.9998)
3. âœ… Reduced prediction error to 4.42 TND (45% improvement)
4. âœ… Implemented professional experiment tracking (7 MLflow runs)
5. âœ… Optimized model through systematic hyperparameter tuning
6. âœ… Cleaned and organized project structure
7. âœ… Created comprehensive, easy-to-run documentation
8. âœ… Prepared for API development (Week 3)

**Status**: Week 2 completed successfully! Clean, production-ready ML pipeline ğŸš€

---

*Last Updated: February 17, 2026*  
*Authors: Iheb Lamouchi & Yassine Nemri*  
*Project: TuniTech Advisor - ML Pipeline Development*
